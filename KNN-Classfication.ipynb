{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "6mhctxlz8_lW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D-Y_1uH9GAO",
        "outputId": "86c44c85-d4a8-469d-ff0f-6c8e83d37caf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum((x1 - x2)**2))\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = [self._predict(x) for x in X]\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "        return most_common[0][0]\n",
        "\n",
        "    def score(self, X, y):\n",
        "        y_pred = self.predict(X)\n",
        "        return accuracy_score(y, y_pred)\n"
      ],
      "metadata": {
        "id": "K6IFjdFX9Irr"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder, num_descriptors=10, resize_shape=(128, 128)):\n",
        "    images = []\n",
        "    features_glcm = []\n",
        "    features_fourier = []\n",
        "    labels = []\n",
        "    for label, class_folder in enumerate(os.listdir(folder)):\n",
        "        class_path = os.path.join(folder, class_folder)\n",
        "        for filename in os.listdir(class_path):\n",
        "            img = cv2.imread(os.path.join(class_path, filename), cv2.IMREAD_GRAYSCALE)\n",
        "            if img is not None:\n",
        "                # Resize the image to a fixed shape\n",
        "                img = cv2.resize(img, resize_shape)\n",
        "                images.append(img)\n",
        "                # Compute GLCM features\n",
        "                #glcm_features = compute_glcm_features(img)\n",
        "                #features_glcm.append(glcm_features)\n",
        "                labels.append(label)\n",
        "    # Check the length of all glcm features and crop them if necessary\n",
        "    #min_length = min(len(feature) for feature in features_glcm)\n",
        "    #features_glcm = [feature[:min_length] for feature in features_glcm]\n",
        "    return np.array(images), np.array(labels)\n",
        "x1, y1 = load_images_from_folder(\"/content/drive/MyDrive/archive2/Data/train\")\n",
        "x2, y2 = load_images_from_folder(\"/content/drive/MyDrive/archive2/Data/test\")"
      ],
      "metadata": {
        "id": "c9zomusf9S3A"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AntColony:\n",
        "    def __init__(self, data, n_ants, n_iterations):\n",
        "        self.data = data\n",
        "        self.n_ants = n_ants\n",
        "        self.n_iterations = n_iterations\n",
        "\n",
        "    def _fitness_function(self, selected_features):\n",
        "        selected_data = self.data[:, selected_features.astype(bool)]\n",
        "        scores = np.sum(selected_data, axis=1)\n",
        "        return np.mean(scores)\n",
        "\n",
        "    def run(self, n_features):\n",
        "        best_features = None\n",
        "        best_score = float('-inf')\n",
        "\n",
        "        for _ in range(self.n_iterations):\n",
        "            ants = np.random.randint(2, size=(self.n_ants, self.data.shape[1]))  # Random initial feature selection\n",
        "            scores = np.array([self._fitness_function(ant) for ant in ants])\n",
        "\n",
        "            # Select top n features based on scores\n",
        "            sorted_indices = np.argsort(scores)[::-1][:n_features]\n",
        "            best_ant_index = sorted_indices[0]\n",
        "\n",
        "            if scores[best_ant_index] > best_score:\n",
        "                best_score = scores[best_ant_index]\n",
        "                best_features = ants[best_ant_index]\n",
        "\n",
        "        # Extract the indices of selected features\n",
        "        selected_indices = np.where(best_features == 1)[0]\n",
        "\n",
        "        # Choose the first n_features if more features were selected\n",
        "        selected_indices = selected_indices[:n_features]\n",
        "\n",
        "        return selected_indices\n"
      ],
      "metadata": {
        "id": "CB7xuGyH9bu7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_block(images, num_blocks_x, num_blocks_y):\n",
        "\n",
        "    rows, cols = images.shape[1:]\n",
        "\n",
        "    block_size_rows = rows // num_blocks_x\n",
        "    block_size_cols = cols // num_blocks_y\n",
        "\n",
        "    images_blocks=[]\n",
        "\n",
        "    # Slice the image matrix into blocks\n",
        "\n",
        "    for image in (images):\n",
        "        sliced_blocks = []\n",
        "        for i in range(num_blocks_x):\n",
        "            for j in range(num_blocks_y):\n",
        "             block = image[i * block_size_rows: (i + 1) * block_size_rows, j * block_size_cols: (j + 1) * block_size_cols]\n",
        "             sliced_blocks.append(block)\n",
        "\n",
        "        images_blocks.append(sliced_blocks)\n",
        "    images_blocks=np.array(images_blocks)\n",
        "\n",
        "    return images_blocks\n",
        "\n",
        "def X_bar(img):\n",
        "\n",
        " XY=[]\n",
        " for i in range (len(img)):\n",
        "    feature_vector=[]\n",
        "    for block in range(len(img[i])):\n",
        "        x_bar=0\n",
        "        y_bar=0\n",
        "        denomenator=np.sum(img[i][block])\n",
        "\n",
        "        numerator1=0\n",
        "        for x in range(len(img[i][block])):\n",
        "            for y in range (len(img[i][block][x])):\n",
        "                numerator1=x*img[i][block][x][y]+numerator1\n",
        "\n",
        "        numerator2=0\n",
        "        for y in range(img.shape[3]):\n",
        "            for x in range (img.shape[2]):\n",
        "                numerator2=y*img[i][block][x][y]+numerator2\n",
        "\n",
        "        if denomenator != 0:\n",
        "           x_bar = numerator1 / denomenator\n",
        "           y_bar = numerator2 / denomenator\n",
        "        else:\n",
        "           x_bar = 0\n",
        "           y_bar = 0\n",
        "        feature_vector.append(x_bar)\n",
        "        feature_vector.append(y_bar)\n",
        "    feature_vector=np.array(feature_vector)\n",
        "\n",
        "    XY.append(feature_vector)\n",
        "\n",
        "\n",
        " XY=np.array(XY)\n",
        " return XY\n",
        "num_blocks_x =6\n",
        "num_blocks_y =6"
      ],
      "metadata": {
        "id": "1tjeIVzd9iwU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#centroid features\n",
        "Xc = np.concatenate((x1, x2))\n",
        "y = np.concatenate((y1, y2))\n",
        "X_block=get_block(Xc,num_blocks_x, num_blocks_y)\n",
        "X_cent=X_bar(X_block)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cent, y, test_size=0.15, random_state=42)"
      ],
      "metadata": {
        "id": "ykUdrmqy9is8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize AntColony instance\n",
        "aco = AntColony(X_cent, n_ants=10, n_iterations=100)\n",
        "\n",
        "# Run feature selection to select the first 40 features\n",
        "selected_features = aco.run(n_features=40)\n",
        "\n",
        "# Print the selected feature indices\n",
        "print(\"Selected feature indices:\", selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oNbNRaM9irC",
        "outputId": "43bf5194-ff6c-42d8-eb65-de79455d6474"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected feature indices: [ 0  1  3  5  7  9 11 13 15 16 17 18 20 21 23 24 25 27 28 29 31 32 34 35\n",
            " 36 37 38 40 42 44 45 46 47 48 49 51 53 55 56 57]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce feature space based on selected features\n",
        "X_selected_train = X_train[:, selected_features]\n",
        "X_selected_test = X_test[:, selected_features]"
      ],
      "metadata": {
        "id": "e9YIZ4569ioq"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the input data\n",
        "X_selected_train_flattened = X_selected_train.reshape(X_selected_train.shape[0], -1)\n",
        "X_selected_test_flattened = X_selected_test.reshape(X_selected_test.shape[0], -1)\n"
      ],
      "metadata": {
        "id": "EVPOhxzo9_uL"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train:\", X_cent.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TLMDZUN-CEz",
        "outputId": "c3df2ec4-fb62-4474-cf10-12d37eb5290f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (531, 72)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "class CustomLDA:\n",
        "    def __init__(self, n_components=None):\n",
        "        self.n_components = n_components\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        self.num_classes = len(self.classes)\n",
        "        self.num_features = X.shape[1]\n",
        "\n",
        "        # Compute class means\n",
        "        self.class_means = np.array([np.mean(X[y == c], axis=0) for c in self.classes])\n",
        "\n",
        "        # Compute within-class scatter matrix\n",
        "        within_class_scatter = np.zeros((self.num_features, self.num_features))\n",
        "        for c in self.classes:\n",
        "            class_data = X[y == c]\n",
        "            class_mean_diff = class_data - self.class_means[self.classes.searchsorted(c)]\n",
        "            within_class_scatter += np.dot(class_mean_diff.T, class_mean_diff)\n",
        "\n",
        "        # Compute between-class scatter matrix\n",
        "        overall_mean = np.mean(X, axis=0)\n",
        "        between_class_scatter = np.zeros((self.num_features, self.num_features))\n",
        "        for c in self.classes:\n",
        "            class_mean_diff = self.class_means[self.classes.searchsorted(c)] - overall_mean\n",
        "            between_class_scatter += len(X[y == c]) * np.outer(class_mean_diff, class_mean_diff)\n",
        "\n",
        "        # Solve the generalized eigenvalue problem\n",
        "        eigvals, eigvecs = np.linalg.eig(np.linalg.inv(within_class_scatter).dot(between_class_scatter))\n",
        "        eig_pairs = [(np.abs(eigvals[i]), eigvecs[:, i]) for i in range(len(eigvals))]\n",
        "        eig_pairs = sorted(eig_pairs, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # Select top eigenvectors based on number of components\n",
        "        if self.n_components is not None:\n",
        "            eig_pairs = eig_pairs[:self.n_components]\n",
        "\n",
        "        # Compute transformation matrix\n",
        "        self.w_matrix = np.array([eig_pairs[i][1] for i in range(len(eig_pairs))])\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.dot(X, self.w_matrix.T)\n",
        "\n",
        "lda = CustomLDA(n_components=2)\n",
        "lda.fit(X_selected_train_flattened, y_train)\n",
        "X_reduced_train = lda.transform(X_selected_train_flattened)\n",
        "X_reduced_test = lda.transform(X_selected_test_flattened)\n",
        "clf = KNN(k=3)\n",
        "clf.fit(X_reduced_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "predictions = clf.predict(X_reduced_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecv7g610-G8X",
        "outputId": "efd5fde8-c56d-4c43-89e1-8d44dbf5d01c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qrW9Xw2-w4O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}